{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Define the dataset class\n",
    "class FacialKeypointsDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.keypoints_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keypoints_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.keypoints_frame.iloc[idx, 0])\n",
    "        image = cv2.imread(img_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        keypoints = self.keypoints_frame.iloc[idx, 1:].values\n",
    "        keypoints = keypoints.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'keypoints': keypoints}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "# Define the transformations\n",
    "class Rescale(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, keypoints = sample['image'], sample['keypoints']\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        img = cv2.resize(image, (new_w, new_h))\n",
    "        keypoints = keypoints * [new_w / w, new_h / h]\n",
    "\n",
    "        return {'image': img, 'keypoints': keypoints}\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        image, keypoints = sample['image'], sample['keypoints']\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'keypoints': torch.from_numpy(keypoints)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.fc1 = nn.Linear(64 * 56 * 56, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 136)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 56 * 56)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "def get_model():\n",
    "    model = Net()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    return model.to(device), criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加入transfer learning的概念，使用resnet50的類神經網路\n",
    "from torchvision import models\n",
    "def get_Resnetmodel():\n",
    "    model = models.vgg16(pretrained=True)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.avgpool = nn.Sequential( nn.Conv2d(512,512,3),\n",
    "      nn.MaxPool2d(2),\n",
    "      nn.Flatten())\n",
    "    model.classifier = nn.Sequential(\n",
    "      nn.Linear(2048, 512),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout(0.5),\n",
    "      nn.Linear(512, 136),\n",
    "      nn.Sigmoid()\n",
    "    )\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    return model.to(device), criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_transform = transforms.Compose([Rescale(224), ToTensor()])\n",
    "train_dataset = FacialKeypointsDataset(csv_file='data/training_frames_keypoints.csv',\n",
    "                                       root_dir='data/training/',\n",
    "                                       transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model, criterion, optimizer = get_Resnetmodel()\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs = data['image']\n",
    "        labels = data['keypoints']\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.view(-1, 136))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 10:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隨機選取一張圖片，並顯示預測的臉部關鍵點\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  # numpy for mathematical operations\n",
    "import cv2  # opencv for image and video processing\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "def show_all_keypoints(image, predicted_key_pts):\n",
    "    plt.imshow(image)\n",
    "    plt.scatter(predicted_key_pts[:, 0], predicted_key_pts[:, 1], s=20, marker='.', c='m')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_output(test_image, test_output):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    ax.set_title('Original Image')\n",
    "    plt.imshow(test_image)\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    ax.set_title('Facial Keypoints')\n",
    "    predicted_key_pts = test_output.data\n",
    "    predicted_key_pts = predicted_key_pts.numpy()\n",
    "    predicted_key_pts = predicted_key_pts * 50.0 + 100\n",
    "    show_all_keypoints(np.squeeze(test_image), predicted_key_pts)\n",
    "\n",
    "# Load the test dataset\n",
    "test_dataset = FacialKeypointsDataset(csv_file='data/test_frames_keypoints.csv',\n",
    "                                      root_dir='data/test/',\n",
    "                                      transform=train_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=4)\n",
    "image, keypoints = next(iter(test_loader))\n",
    "output = model(image)\n",
    "visualize_output(image, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "macvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
